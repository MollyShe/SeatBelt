# Model parameters
latent_dim: 512
epsilon: 0.05

# Training parameters
batch_size: 32
num_epochs: 100
learning_rate: 0.0002
beta1: 0.5
beta2: 0.999

# Data parameters
data_dir: "path/to/your/dataset"
num_workers: 4

# Logging and checkpointing
checkpoint_dir: "checkpoints"
log_interval: 100
checkpoint_interval: 5

# Target encoder
target_encoder_path: "path/to/target/encoder.pt"

# Resume training (optional)
resume_checkpoint: null  # or path to checkpoint file